{"pages":[{"title":"About","text":"一倍工程師在經歷了一番努力之後，成為了一點五倍工程師。 他每天加班四小時。 My public key: 1234567891011121314151617181920-----BEGIN PGP PUBLIC KEY BLOCK-----mDMEWzRiaBYJKwYBBAHaRw8BAQdAork0AXgHa/7KPcnYvTZLmswyIYC5SNU1pWQJHU/WC/y0H1dlaWRhIEhvbmcgPHdkaG9uZ3R3QGdtYWlsLmNvbT6IlgQTFggAPgIbAQULCQgHAgYVCgkICwIEFgIDAQIeAQIXgBYhBLpheEMt5aUAqCgg9scosr3JdW4FBQJgQ5uwBQkSN6HIAAoJEMcosr3JdW4FEc4A/iqX61c5lwfuHwfvJ1u+8KEF7QUfYhoobjmpfM/4Sk/uAP9Dx0WfW9EN0I429FjzKOUg7msjX7mcHalpNasBeNZHBLgzBF7Sis8WCSsGAQQB2kcPAQEHQAk7WSboerZhn6raITZvdDirbgO7SlPGCAR7V1YtP048iPUEGBYIACYCGwIWIQS6YXhDLeWlAKgoIPbHKLK9yXVuBQUCXtKLkQUJBKKGwgCBdiAEGRYIAB0WIQSz0YvHVafhHsjzqQKMwunPs74nDAUCXtKKzwAKCRCMwunPs74nDEyRAQC9E1AXlN0/uqSoOsrU0oJceicHgnYTT06CrcK4EXGCuQD/aeAt3P34j03sx5W80+xyrIBvAQvMbkVhkI+mRHG0bQ0JEMcosr3JdW4F6hwA+wTA38zfrw+FYjce1SuVxQBMeGbjlglZVNM7GvwcZkyQAPkBbKDhiKGAwHw2/3d1TGsnTe1YyRndEysyQApZjTR+A7g4BF+aYkcSCisGAQQBl1UBBQEBB0Au9XV4/WzaaUX3A1pDJIQzU7EQczLujJ5eyZBcgGR0egMBCAeIfgQYFggAJhYhBLpheEMt5aUAqCgg9scosr3JdW4FBQJfmmJHAhsMBQkDwmcAAAoJEMcosr3JdW4FovgBANqzGusL//4Rqu3v0DC/s8ZbMhIiL0jF41VTXKa6vAaDAQDIxX2A5V3QettMyLz/j4GpdXLmxh7R6n4kajNuiEAoBA===Covm-----END PGP PUBLIC KEY BLOCK-----","link":"/about/index.html"}],"posts":[{"title":"保護存在檔案系統上的 Docker 登入密碼","text":"在企業內部的工作環境中，常會碰到需要存取 private registry 上的 image 的狀況。 以 Docker 的工作流程來說，一般要透過執行 docker login 來存取 private registry。 不過，若事先毛設定好 docker credential helper，執行 docker login 會導致 我們的密碼 / API token 直接以明文的方式寫在檔案系統上。 這篇筆記說明如何在 Linux 環境下安裝與設定 docker credential helper。 Installation至 docker/docker-credential-helpers 的 GitHub release 頁面下載最新版本的 docker-credential-secretservice。 1curl -L https://github.com/docker/docker-credential-helpers/releases/download/v0.6.3/docker-credential-secretservice-v0.6.3-amd64.tar.gz &gt;secretservice.tar.gz 解壓縮並把執行檔放到任意一個 PATH 資料夾內。 123tar -zxv -f secretservice.tar.gzchmod +x docker-credential-secretservicemv docker-credential-secretservice ~/.local/bin Configuration為了讓 docker 工具知道我們要用 credential helper，需要調整家目錄下的設定檔。 在設定檔 ~/.docker/config.json 內加入 credsStore 設定。 1$EDITOR ~/.docker/config.json 123{ &quot;credsStore&quot;: &quot;secretservice&quot;} 註: 此資料夾和 JSON 檔案可能不存在。若沒有自己創一個即可。 註: 根據文件，此欄位的值與是 helper binary 的後綴對齊，因為 Linux 環境使用的 binary 是 docker-credential-secretservice 所以需要填入的值爲 secretservice Usage如果已經有登入過某 registry，需要手動登出。 1docker logout registry.example.com (重新) 登入該 registry。 1docker login registry.example.com 檢視 ~/.docker/config.json 並確認對應的身分紀錄是空白的。 12345{ &quot;auths&quot;: { &quot;registry.example.com&quot;: {} }} 若有安裝 Seahorse 程式的話，此時可以看到 secret 被放在 Login keyring 中。 如果設定錯誤的話，登入資訊會以編碼過的方式呈現在該紀錄中。 1234567{ &quot;auths&quot;: { &quot;registry.example.com&quot;: { &quot;auth&quot;: &quot;c3R...zE2&quot; } }} Future Reading docker login - Docker Documentation docker/docker-credential-helpers GNOME/Keyring - ArchWiki","link":"/2021/03/04/docker-credential-helper.html"},{"title":"關於電子報一鍵退訂","text":"前言前先日子在 Gmail 內整理信件時，赫然注意到了一件事情： 某些訂閱來的電子報，在寄件者名字的右邊有個退訂的文字可以按！ 但讓我訝異的其實不只是這個退訂文字.. 按下退訂文字後，Gmail 會彈出一個視窗給我，裡頭會問我是不是確定要退訂此電子報，以及一個藍色的退訂按鈕。 神奇的是，當我按下這個按鈕後，Gmail 直接告訴我，你已經退訂了此電子報！ “You unsubscribed from xxxxxx..” 某人: 奇怪… 一般不是會連到某個電子報寄送方的頁面，然後讓我點個確認之類的嗎？ 既然 Gmail 有辦法在不離開 web mail 介面的情況下，幫我完成退訂的動作，那大概是有某種標準程序，可以讓 mail 供應商自動化的幫我處理吧？ 於是乎，本著實事求是的精神，就有了今天這篇文章。 工程師的直覺注意到有這個退訂按鈕可以按之後，我就開始一封信一封信看，有退訂按鈕的都來給他點看看，看會發生什麼事。但我很快地就注意到… 並不是每個有按鈕可按的 Gmail，都可以直接幫我完成退訂。 像是 Linkin 和 Google Map 寄來的信，都是會幫你打開某連結，讓你到該頁面去做後續處理。 但不管如何，既然 Gmail 可以幫我把這個連結取出來，大概是有某種標準的 mail header 來記錄這些資訊吧？把 Linkin 那封原始信件點開來一看，發現了這個東西 1List-Unsubscribe: &lt;https://www.linkedin.com/e/v2?e=6f948d7f&amp;t=ad69-4827&amp;...&gt; 再把這個 List-Unsubscribe 拿去查，就找到一篇 RFC 了 123456789Network Working Group G. NeufeldRequest for Comments: 2369 NistoCategory: Standards Track J. Baer SkyWeyr Technologies July 1998 The Use of URLs as Meta-Syntax for Core Mail List Commands and their Transport through Message Header Fields RFC 2369 “The Use of URLs as Meta-Syntax for Core Mail List Commands”。仔細一讀後發現，以前的人為了用 mail 標準化 mail list 的各種處理動作，還下了不少苦心。 XD 光是這份 RFC 內有提到的部分 header 就有: List-Help: 所有和此 mail list 相關的資訊都從這邊取得 List-Unsubscribe: 使用者快速退訂的方式 List-Subscribe: 使用者快速訂閱的方式 List-Post: 使用者發表文章至此 mail list 的方式 其中的 List-Unsubscribe 就是我們要的東西。參照 RFC 說明，這個 header 內可以放 HTTP 的連結或 mailto 的連結。這樣看起來，如果是 HTTP 連結，Gmail 就會幫我們連上該頁面。而那些沒有額外跳出頁面的，大概就是 Gmail 直接幫我們寄退訂信件了吧。 12List-Unsubscribe: &lt;http://www.host.com/list.cgi?cmd=unsub&amp;lst=list&gt;, &lt;mailto:list-request@host.com?subject=unsubscribe&gt; 開始驗證為了確認上面的猜想，我又點了封有退訂按鈕且不會跳出額外頁面的信件。這次的實驗對象是 The Hacker News。在點擊退訂之後，在我的寄件信箱內找到 Gmail 自動幫我產生的信件，Gmail 不只有幫我寄這封信，連信件主旨和內文都幫我填好好的。 XD 123456# 按下退訂後，我寄出的信 (省略部分 header)To: f081fcde-0c7e-4617-afaf-c0c35eeea170@unsubscribe.netline.comSubject: UnsubscribeContent-Disposition: inline$You will be unsubscribed from this list within ten days of sending this reply 在回去看一下原本納封電子報的原始信件，果然在 header 內找到這對應的 List-Unsubscribe mailto 連結，且信件主旨和信件內文和這個連結後方帶的資訊完全吻合。 12# The Hacker News 信件的 List-Unsubscribe headerList-Unsubscribe: &lt;mailto:f081fcde-0c7e-4617-afaf-c0c35eeea170@unsubscribe.netline.com?subject=Unsubscribe&amp;body=$You%20will%20be%20unsubscribed%20from%20this%20list%20within%20ten%20days%20of%20sending%20this%20reply&gt; 看到這裡，似乎是真相大白了。參與制定 RFC 的人們真偉大！趴機趴機趴機！ 用 HTTP(S) 連結做退訂的會開一個 HTTP Get 請求，讓使用者到某頁面按退訂；而那些用 mailto 連結的，mail agent 可以幫我自動寄出退訂信件，於是達成一鍵退訂的功能！ 不過… 我剛剛好像也一鍵退訂了 Pinkoi 的電子報，但好像沒有看到自動寄出的信件？ 案外案: RFC 8058原本以為該懂得都懂了，一切就是那麼的單純，都在我的掌握之中。 直到我注意到 Pinkoi 的電子報 (X 在實驗的過程中，Pinkoi 也像 The Hacker News 一樣，可以在 mail 介面中直接完成退訂。但不一樣的是，mail 系統沒有自動幫我產生並寄出退訂用的信件。 …看來這當中一定還有些我不知道的東西！ 有了先前的經驗，這次很快地把 Pinkoi 電子報的原始信件打開來看，並直接搜尋 unsubscribe 字眼。一搜不得了，看到了一個沒在 RFC 2369 中出現的 header: List-Unsubscribe-Post 。拿這個 header 去找 RFC，結果找到了這個東西 1234567891011121314Internet Engineering Task Force (IETF) J. LevineRequest for Comments: 8058 Taughannock NetworksCategory: Standards Track T. HerkulaISSN: 2070-1721 optivo GmbH January 2017 Signaling One-Click Functionality for List Email HeadersAbstract This document describes a method for signaling a one-click function for the List-Unsubscribe email header field. The need for this ... “Signaling One-Click Functionality for List Email Headers”，嗯.. 看來這就是我要的東西了… 在經過快速地閱讀之後，這個 RFC 的部分動機大概是這樣的 防毒軟體一般會掃過所有在信件內的 HTTP(S) 連結。電子報供應商為了避免防毒軟體不小心幫使用者退訂，通常會把連結做成需要使用者互動的網頁，像是在頁面中放個額外的確認按鈕等。但此作法又會造成信件軟體或信件服務商，無法在取得使用者的同意後，自動化的幫使用者退訂電子報。因此，需要訂出一個標準的方法，讓 HTTPS 的退訂連結也可以達成一鍵退訂。 這動機看起來是很清楚了.. (其實還有部分有關垃圾信的處理問題，這邊就不翻譯了)。不過究竟該怎麼做一鍵退訂呢？ 根據 RFC 8058 的描述，信件若要用 HTTPS 連結做一鍵退訂，至少需要滿足以下幾點: List-Unsubscribe header 內至少有一 HTTPS 連結 需要額外有 List-Unsubscribe-Post header，且其值必須為 List-Unsubscribe=One-Click 必須有 DKIM 簽章來驗證上述兩個欄位 第一點是挺合理的，這個 RFC 是 2017 年出來的，大概不會有人還想推 HTTP 連結了。而第二點的 List-Unsubscribe-Post header，是要告訴 mail 軟體說 “我這個連結可以吃 HTTP POST 請求喔！喔對了記得 POST 過來時內容要帶 List-Unsubscribe=One-Click 喔”。至於第三點，單純是要確保上述兩個 header 是沒有被竄改過的。 因為有講好 client 應該用 POST 方法去戳這個連結，於是電子報的 server 就可以很清楚的分辨，哪些請求是防毒軟體不小心誤發的，哪些請求是使用者真的想退訂才發的。且因為有清楚的表達意圖，這個 HTTPS POST 請求也不需要回一個要使用者額外互動的頁面，server 可以在收到請求後，直接處理使用者的退訂動作。 1234567891011# 假設信件內有以下 headerList-Unsubscribe: &lt;https://example.com/unsubscribe/opaquepart&gt;List-Unsubscribe-Post: List-Unsubscribe=One-Click# 那 mail 軟體(提供商) 可以簡單透過以下 HTTPS POST 幫使用者退訂POST /unsubscribe/opaquepart HTTP/1.1Host: example.comContent-Type: application/x-www-form-urlencodedContent-Length: 26List-Unsubscribe=One-Click 可喜可賀.. 可喜可賀 XDD 其他軟體的支援性和 Google 的工人智慧發現有這個標準後，其實很好奇其他的 web mail 或信件軟體對這些 header 的支援度如何。無奈的是，沒找到比較完整的整理結果，似乎也沒多少人在意這個東西。 XD 不過從唯一一份找到的資料來看，在 iOS Mail, Gmail, Outlook 與 Yahoo Mail 四者中，mailto 的退訂連結都有支援，而 RFC 8058 所定義的一鍵退訂則是只有 Gmail 可以做到。(至少在 2018 年 11 月還是如此) 另外，我也發現到，即使有些信件完全沒有 List-Unsubscribe header，Gmail 仍然可以生出退訂的按鈕給使用者按，Twitter 的通知信件即是一例。Twitter 的信件 header 內沒有相關的資訊，但 Gmail 可以從信件內文內把退訂的連結 parse 出來。至於這部分是 Google 偉大的工人智慧，還是有一些我還不知道的標準可參考，這我就還沒研究到了。 結論這篇文章基本上是把某個週末因為三分鐘熱度而去學的東西記錄下來。但過了兩週之後再回來看，其實好像也不是多重要的東西。就算今天我們不知道有這個標準，或是根本沒注意到有這個功能，日子也還是過得很好 (? 但是.. 小工程師滿足自己的好奇心後，心中所獲得的那種成就感，是無可取代的！","link":"/2019/08/31/email-one-click-unsubscribe.html"},{"title":"利用 GitHub Page 經營 Blog","text":"如果要用一句話來簡單說明 GitHub Page，那基本上就是 指定一個 Git 版本庫來作為存放網站資源的地方，然後讓 GitHub 幫你把網站架起來。 任何人只要申請一個 GitHub 帳號，都可以免費的享有這個服務。 當然，考量到 GitHub 只是把我們放在版本庫上的檔案，讓別人透過瀏覽器瀏覽， 那種需要用到資料庫的可互動網站基本上是很難達成。 但若我們只是要經營一個部落格，或是存放專案文件等靜態網站時，GitHub Page 就會是個很合適且方便的選擇。 本文會粗淺的介紹如何利用 GitHub Page 來經營自己的 Blog， 以省去自行架設機器的各種煩惱。 :D GitHub Page 的類別目前 GitHub Page 有兩類的站台，一類是 User Page、另一類是 Project Page。 (其實還有 Organization Page，但這邊就不花時間贅述) User Page 與 Project Page 最主要的差別在於專案名稱的限制，與網站的 URL 格式這兩點。簡單整理如下 User Page 特點: 專案名稱須為 &lt;username&gt;.github.io，其中 &lt;username&gt; 即為 GitHub 帳號的使用者名稱。 站台會擺在 http(s)://&lt;username&gt;.github.io 供他人瀏覽 Project Page 特點: 專案名稱沒有限制。 若假設專案名稱為 &lt;projectname&gt; 則 站台會擺在 http(s)://&lt;username&gt;.github.io/&lt;projectname&gt; 供他人瀏覽 因為專案名稱的限制，一個 GitHub 帳號只能有一個 User Page 但可以有多個 Project Page。 更詳細的介紹請參考 官方網站的說明 GitHub Page 使用方式GitHub Page 的使用方式也可以簡單分成兩種。 第一種是直接建置好的整個網站直接 push 到 GitHub 上，供使用者瀏覽。 若我們需要架一個 Blog，可以先用 Markdown 等 markup language 撰寫文章， 之後利用 Jekyll(Ruby)、Hugo(Golang) 或 Hexo(JS) 等靜態網站生成工具， 建出一個 Blog 網站並 push 上去。 又或我們需要 host 一個專案文件站台時，可以將 Doxygen 或 Sphinx 等工具 產生出的網站推上 GitHub。 12345678 + Local Project | GitHub Project | github.io site ++----------+ +--------+ +------+ User| Markup | Build | Site | Push | Site | Browse| config.. | +------&gt; | | +-----&gt; | | +-------&gt;+----------+ +--------+ +------+ 如果我們是使用 Jekyll 來建置我們的網站，那 GitHub Page 有提供我們第二種用法。 我們可以將 Markup 和其他 Jekyll 需要的設定檔 push 上 GitHub，讓 GitHub 幫我們 建置網站，並在 github.io 網域上放出網站供人瀏覽。 12345678 + +Local Project | GitHub Project | github.io site | | + ++----------+ +----------+ +------+ User| Markup | Push | Markup | Build | Site | Browse| config.. | +----&gt; | Config.. | +-----&gt; | | +-------&gt;+----------+ +----------+ +------+ 第二個做法的缺點是，GitHub 只支援 Jekyll 這套工具，其他同性質的工具的不支援。 但相對來說也有優點，即是我們不須把工具建出的網站內的所有檔案都進到 commit 中。 (在 git project 中看到許多無意義 diff 實在不是工程師所樂見的事情 XD) 針對這兩個方式的更詳細說明，也請見官方文件 使用 Jekyll 不使用 Jekyll 簡單的流程說明接下來會介紹使用 Jekyll，並讓 GitHub 幫忙 build 與 host 網站的簡單步驟。 參照 官方介紹 的說明，最簡單的方式，其實只需要 我們點開 project 的 GitHub 設定頁面，找到 GitHub Page 的設定選項，設定一個 Jekyll 使用的主題，並用 Markdown 寫一個首頁文章即可。 用此方法會在專案內產生首頁的 index.md 檔案及一個 Jekyll 的設定檔 _config.yml。 檔案內僅一行你選的主題名稱 1theme: jekyll-theme-minimal 但基本上，一個 完整的 Jekyll 專案 不會只有這兩個檔案，到最後我們還是得把其他需要的檔案生出來。 所以個人推薦使用下述方法建立我們的專案。 (假設我們已經裝好 Git 和 Jekyll 等工具。) 建立 Git 專案 12mkdir website &amp;&amp; cd websitegit init 在專案資料夾建立 Jekyll 的 template 檔案 1jekyll new . 此時應該會看到 jekyll 預設產生的檔案 12$ ls404.html about.md _config.yml Gemfile Gemfile.lock index.md _posts 將所有產生的檔案 add 並 commit 起來 (要不要略過 Gemfile.lock 看個人需求) 12git add .git commit 之後將專案 push 上 GitHub，並至專案設定內啟用 GitHub Page 即可。 沒意外的話，大概十秒內就可以在對應的 URL 看到生成好的網站了。 有關 Jekyll 的安裝說明或其他細部設定，可參考 官方網站。 在 GitHub Page 服務上使用個人客製的網址如果不想使用 &lt;username&gt;.github.io 來提供自己的網站，而是透過自己購買的域名， 所需的麻煩差事 GitHub Page 也幫我們做得好了。 在 GitHub 專案開啟 GitHub Page 功能後，可以看到一個額外的選項 Custom domain， 可以填入我們可控制的 DNS hostname。 假設我們想在 blog.example.com 提供我們的網站，只需要在 DNS 設定中加入一筆 CNAME，將 blog.example.com 指向 &lt;username&gt;.github.io。並去 GitHub Page 所用的 GitHub 專案設定頁面內，在 Custom domain 欄位內填入 blog.example.com 即可。 設定完後，即可透過 blog.example.com 瀏覽我們要的網站。 同時 GitHub 也會在一天內生出對應的 SSL 憑證，即使透過 blog.example.com 瀏覽， 也可以享有 HTTPS protocol 帶來的安全性。 :D 雜談大概從 2018 十月開始，小弟我在與朋友以及公司同事談話後，漸漸有了經營自己 Blog 的想法。 經歷了數週的拖拉散漫後，終於在 2018 十二月底刷卡買了自己的 domain，並利用 GitHub Page 架設好 Blog。但因為一直沒想好要寫什麼文章，於是第一篇就先來寫寫 我自己的架站筆記。 期許自己未來能不斷產出新文章，成為一位散發正面能量的一倍工程師。","link":"/2019/01/12/github-page-blog-howto.html"},{"title":"GitHub Pages 與 GitLab Pages 架設 Blog","text":"筆者最近把個人 blog 的產生工具從 GitHub Pages 預設的 Jekyll 換成 Hexo，有了一點心得。 而且不只 GitHub Pages， 筆者在公司業務中也有大量使用 GitLab Pages 來產生文件及測試報表，算是有累積不少經驗。 趁著印象還深刻時，寫點筆記，替這兩個相同性質的服務做基本的介紹。 Pages 服務與 Static Site GeneratorGitHub / GitLab Pages 可以將一組靜態網頁內容 (html, css, js 等)，透過 GitHub / GitLab 的伺服器，host 在某個 URL 底下。 網頁產生工具 (Static Site Generator, 下稱 SSG) 則是 一個可以將用 Markdown 撰寫的文章，轉化成漂亮的靜態網頁內容的工具。常見的 SSG 有 Jekyll(Ruby), Hugo(Go), Hexo(JavaScript) 等。 若將 SSG 工具與 GitHub / GitLab Pages 服務，搭配使用， 寫作者只需要寫寫簡單的 Markdown 並 push commit，就能得到一個漂亮的 blog 或是文件網頁。 筆者的個人 blog 及公司的工作筆記即是使用這類流程架設。 整體流程大概如下圖所示: 123456789 + GitHub + github.ioLocal Project | Project | site | GitLab | gitlab.io + ++----------+ +----------+ Build &amp; +------+ User| Markup | Push | Markup | Deploy | Site | Browse| config.. | +----&gt; | Config.. | +-------&gt; | | +-------&gt;+----------+ +----------+ +------+ GitHub PagesGitHub Pages 基本上會有兩種主要的使用方式。 可以直接使用 GitHub Pages，或是透過 GitHub Pages 的 Jekyll 整合功能。 前者需要的技術背景與設定步驟均較複雜，後者較簡單但缺少了根據個別需求調整的機會。 Native GitHub Pages若直接使用 GitHub Pages，使用方式是: 將 SSG 產生的網頁擺放至某 branch (預設為 gh-pages) 的 / 或 /docs 目錄。 每次該 branch 被更新時，GitHub 就會將最新版本的網頁內容， 呈現在 https://&lt;username&gt;.github.io/&lt;project&gt; 連結下。 早期這個 push brach 的動作是蠻麻煩的，但後來有了 GitHub Action 之後， 產生網站和後 push branch 的動作都可以在 GitHub 提供的環境完成，非常方便。 筆者個人使用的 job 描述檔如下: 12345678910111213141516171819202122232425262728# .github/workflows/blog.yamlname: build-and-deploy-blogon: push: branches: [ &quot;master&quot; ] pull_request:jobs: blog: runs-on: ubuntu-20.04 steps: - name: Checkout uses: actions/checkout@v2.3.4 - name: Setup Node.js environment uses: actions/setup-node@v2.1.5 with: node-version: 12.x - name: Install dependent packages run: npm install - name: Build blog posts run: npm run build - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public 若不想使用 GitHub 提供的 domain，也可以參照 官方文件， 使用自己購買的 domain 來架設網站。 只要設定完成，GitHub 也可以一併幫使用者申請 custom domain 需要的 HTTPS 憑證。 比方說筆者的 blog 原本可存取的位置應是 https://wdhongtw.github.io/blog，但有設定 custom domain 後，目前是透過 https://blog.bitisle.net 來存取架在 GitHub Pages 上的 blog。 GitHub Pages Jekyll前述 (Native) GitHub Pages 的使用方式會需要自己 push branch。 但若 GitHub 偵測到 project 使用的 SSG 是 Jekyll，GitHub 會自動處理產生網頁以及 後續部屬到 https://&lt;username&gt;.github.io/&lt;project&gt; 的工作。 (連 gh-pages branch 都省了，整個 project 會非常乾淨。) 此方法相當容易上手，也是 GitHub Pages 教學文件預設的使用方式。但因為產生網站的 環境是由 GitHub 協助處理，能使用的 Jekyll plugin 自然也是受到限制。 說是受到限制，但以一般使用情境應該也很夠了。諸如 RSS feed, sitemap, Open Graph metadata 等現代 blog 必備的功能都有自帶。 若想知道有那些 Jekyll plugin 可用，可至 Dependency versions | GitHub Pages 查閱。 Compare Native GitHub Page with GitHub Pages and Jekyll簡單比較上述兩種方式如下 GitHub Page GitHub Page with Jekyll SSG Tool on your choice only Jekyll Deployment push generated site done by GitHub Customization any plugins of SSG limited Jekyll plugin list GitLab PagesGitLab Pages 與 GitHub Pages 一樣，有將 SSG 產生的網頁 host 在特定網址的能力。 以 GitLab 官方 host 的站台來說，網站會放在 https://&lt;username&gt;.gitlab.io/&lt;project&gt; 下。 (私人或公司 host 的 GitLab instance 就要看各自的設定) 與 GitHub 不同的是，GitLab Pages 並不是透過 push branch 的方式部屬， 且沒有針對特定 SSG 提供更進一步的自動部屬功能。 GitLab Pages 的使用方式是基於 GitLab CI Pipeline 的架構設計的。若想要部屬 網站，一般的使用方式是在 pipeline 內產生網頁，接著將網頁內容擺放至為特定 job (pages) 的特定 artifacts 目錄 (public) 中。 一旦有 pipeline jobs 達成此條件。 GitLab 就會 把網頁內容部屬到對應的網址下。 筆者個人使用的 job 描述檔如下: (因為 GitHub Action 與 GitLab CI 的架構差異，寫起來比較簡潔) 12345678910111213# .gitlab-ci.ymlpages: image: ruby:3.0.1 stage: deploy before_script: - bundle install script: - bundle exec jekyll build --destination public --baseurl &quot;$CI_PAGES_URL&quot; artifacts: paths: - public only: - master 至於其他 GitHub Pages 有的功能，如 custom domain，自動申請 HTTPS 憑證等，GitLab Pages 也都有。 記得去 project 設定頁面設定即可。 Conclusion在 2008 年 GitHub Pages 剛推出時，使用者都要自己手動 push gh-pages branch。 後來 GitLab 推出基於 GitLab CI 的 Pages 服務之後，GitHub Pages 使用體驗相較之下可說是非常糟糕。 但後來隨著 GitHub Actions 服務推出，以及社群維護的高品質 Pages 部屬 Action 出現。 GitHub / GitLab Pages 的使用體驗已經變得相當接近。 其他像是 custom domain 以及 HTTPS 的支援也都是免費的基本功能。 基於上述原因，許多早期的 比較文章 其實已經沒什麼參考價值。 若現在想架設新的 blog 等站台，只要選擇自己習慣的平台即可。 References GitHub Pages Documentation - GitHub Docs GitLab Pages | GitLab","link":"/2021/06/06/github-pages-gitlab-pages.html"},{"title":"Google 更新 Go 的社群行為準則","text":"昨天 Go blog 上出新文章，說要更新 Code of Conduct。 一直一來覺得每個社群的 CoC 都寫得差不多，不外乎是要互相尊重、開放透明、建設性發言等等。 也因為都差不多，平常也不會去細看。反正就是些正常人該有的道德觀。 因此，看到說要更新 Code of Conduct 讓我感到有點好奇。 讀一讀讀下去，其實這次 Go community 的 CoC 就是新增一條： Be responsible. What you say and do matters. Take responsibility … 沒想到連這個都要寫進 CoC …。可能 Go 的核心開發團隊看 issue 真的看到心累了？ XD See: Code of Conduct Updates - go.dev","link":"/2021/09/23/golang-coc-update.html"},{"title":"Golang 1.18 Generics 終於來臨","text":"今天 Golang 1.18 終於正式釋出啦！ 我們終於有辦法在 Golang 裡做 generic programming 啦！ Golang 是一個近 10 年快速竄紅的程式語言，但在很多面向其實還是非常土炮。 得靠後續社群不斷的討論與貢獻才達到一個比較完善的水準。 像是.. context package in Golang 1.7: 解決 long job cancelling 的問題 errors package in Golang 1.13: 滿足其他語言常見的 error 嵌套需求和提供統一的判斷方式 Generic support in Golang 1.18: 提供開發者實作各種型無關演算法的機會 一直以來，在 Golang 的標準函式庫中，碰到類型無關的抽象問題時，最後給出來的解法大概就兩種 所有 input / output 參數都定義成 interface{}，大家一起把型別檢查往 run-time 丟 同一個 class / function 對於常用的 data type 通通實作一遍 前者最典型的大概就是 sync 這個函示庫，後者.. 大家應該都看過那個慘不忍睹的 sort.. 不過這些都是過去式了，從今天開始，大家都可以寫自己想要的 generic code / library / framework。 :D Usage基本語法很簡單，只要在想做成 generic 的 function / struct 後面多加一個 [T TypeName] 即可， TypeName 是用原本就有的 interface{...} 語法來表示，可以自己描述這個 generic function / struct 支援的型態必須滿足什麼樣的介面。 以 Python style 的 sort by key 當例子。 我們可以定義一個 generic 的 sort function，並且明定送進來的 list 內的每個元素需要支援一個 Key 函示， 作為排序時的根據。 範例 code 如下 1234567891011121314151617181920212223242526272829303132333435363738package maintype Keyable interface { Key() int}func Sort[T Keyable](items []T) []T { if len(items) &lt;= 1 { return items } pivot := items[0] less, greater := []T{}, []T{} for _, item := range items[1:] { if item.Key() &lt; pivot.Key() { less = append(less, item) } else { greater = append(greater, item) } } return append(append(less, pivot), greater...)}type Person struct { Name string Age int}func (n Person) Key() int { return n.Age}func main() { persons := []Person{{Name: &quot;alice&quot;, Age: 33}, {Name: &quot;bob&quot;, Age: 27}} persons = Sort(persons)} 在這個範例中，Sort 要求送進來的 []T 當中的 T 要實作 Keyable 介面 (提供 Key method)。 當我們想排序一堆 Person 時，我們可以在這個 Person 物件上定義 Key method，取出 Person 的年齡。 完成之後，我們就可以依年齡來排序 []Person 了。 期許自己未來可以多加利用這個遲來的功能.. XD References Go 1.18 Release Notes Tutorial: Getting started with generics","link":"/2022/03/16/golang-generics-coming.html"},{"title":"延長或縮短 GPG 金鑰的過期時間 (Expiration Time)","text":"筆者在 2018 年的時候開了第一個真的有在長期使用的 GPG 金鑰。 因為年少輕狂不懂事，當時特別把 primary key 設定成永遠不會過期。 但演算法可能在未來被發現漏洞，電腦的運算能力也會越來越好， 一把不會過期的 GPG 金鑰是先天上不合理的存在。 考量到此問題，筆者後來又再修正了該金鑰的過期時間， 以及整理這篇筆記… GPG Key 可以延展過期時間？我想這應該是熟悉 X.509 憑證生態系的人最為驚訝的一件事情了。 我發現幾位公司主管並不知道這件事情，也促使我在經過一段時間後回來整理這篇文章。 事實上，GPG key 不只是可以延展過期時間，這也是一般推薦的最佳慣例。 People think that they don’t want their keys to expire, but you actually do. Why? Because you can always extend your expiration date, even after it has expired! See: OpenPGP Best Practices - riseup.net 使用者應該設一個較短的有效時間，並在後續有需要時延展過期時間。 GPG key 可以自己修改金鑰的過期時間，是因為 GPG key 和 X.509 憑證有著本質上的區別。 GPG key 的產生是透過 primary key 的 self-signature， 而 X.509 憑證的簽署是由公正的第三方 CA 進行。 X.509 憑證的過期時間是 CA 幫你簽署憑證時決定，自然無法隨意修改， 大家也很習慣這件事情，但 GPG key 就不一樣了。 GPG key 的有效時間是透過 key 的 self-signature 內所記載的時間決定。 只要 primary (private) key 沒有遺失，持有者隨時可以重新自簽並修改時間。 只要認知到兩者本質上的差異，可以修改過期時間這件事情也就很好理解了。 他人如何認定過期時間？既然 GPG key 可以隨時重簽修改過期時間，那對他人來說， 該如何判定某把 key 究竟什麼時候過期呢？ 規則很簡單 The latest self-signature takes precedence See: Key Management 若是透過 gpg tool 修改過期時間，舊的 self-signature 會被刪掉。 因為只有一個 self-signature，修改完之後，只要重新把 key export 給他人， 他人就可以知道新的過期時間。 若不是透過信賴管道直接把新簽的 key 給他人，而是透過 GPG key server， 狀況會有點不一樣。 基於安全考量，GPG key server 是不允許部分或完全刪除 key 的，MIT 名下的 key server 還特別寫了一篇 FAQ 來說明這件事。 對於一把已存在的 key，使用者只能推新的 sub key 或新的 signature 上去。 因此，他人透過 key server 取得 key 時，也會拿到多個 signature。 好在 signature 本身也有時戳，根據上述 “後者為準” 的規則，他人就可以知道 正確的過期時間是何時。 有興趣的可以查看筆者的 GPG key 來確認這個行為 12345678gpg --keyserver keys.gnupg.net --recv-keys C9756E05# Get key from key servergpg --export C9756E05 | gpg --list-packets# One signature has &quot;key expires after ...&quot; while another doesn'tgpg -k C9756E05# Validate that the key indeed expires at some time 或是可以直接去 GnuPG 官方的 key server 查看: Search results for ‘0xc728b2bdc9756e05’ 結語翻閱文件研究的過程，慢慢感受到到 GPG 這個扣除 X.509 之外唯一成熟的 PKI 生態系，究竟有多麼偉大。同時也看到很多值得細讀的 guideline 文件。 若有時間，真的該來好好吸收整理。","link":"/2021/05/06/gpg-key-extend-expiration-date.html"},{"title":"Kubernetes Audit Log 使用筆記","text":"我在公司的工作環境中，有些業務需要部屬服務在 Kubernetes (下稱 K8s) 上。 因此在專案早期，部門內的同事自架了 K8s cluster 來開發。 隨著時間流逝，各個 RD 開始上手 K8s 操作後，每天都有人在對 K8s 的 master 開發環境做修改。 於是部門內開始產生一些令人煩躁的對話 我看 K8s 上面有裝了某個 CRD，但沒有裝對應的 service 來用這個 CRD，這個是你裝的嗎？ Test namespace 裝了一個 Ingress rule 產生衝突了，那個 rule 是誰裝的？ … 這些對話的共通點是：想知道 K8s 的狀態改變是誰造成的。 但在部門自架的環境內，因為大家共用了一個 kubeconfig，所以根本無從找起.. 於是我想辦法把開發用的 K8s 環境設定好 auditing log 的功能，並留下這篇筆記 Audit 目標要做 audit 來確認每個人做了什麼操作，我需要達到兩個目標 不同人員需要使用不同的身分存取 K8s API server API server 需開啟 log 且 log 需保存在 persistent storage 上 身分驗證方式比較參考 K8s 的 Authenticating 官方文件，在不依賴外部服務的情況下，大概有三種身分驗證的方式 X509 Client Certificate Static Token File Service Account Tokens 以下分別介紹各方式的優缺點 X509 Client Certificate此方式依賴 TLS 的 client verification 功能，只要你有正確的憑證塞在 kubeconfig 裡即可使用。 一般在做 cluster 初始化過程中拿到的 admin kubeconfig ，其內容即屬這一類。 此方式的優點為 若採取嚴謹的使用者自行產生 key-CSR pair 再給 CA 簽署流程，因為僅使用者有 private key，出事時有高度信心一定是該使用者所為 除了自己的 user name 外，使用者可以從自己的憑證中直接確認操作 K8s 時會有那些 group 身分 憑證內 subject 的 CN 對應 K8s user name, O 對應 K8s group name 此方式的缺點為 K8s 不支援 X509 原生的 certificate revocation 功能，若有特定 client 憑證有問題，得整個 CA 換掉重來 Upstream issue: Support for managing revoked certs (opened for 5 years) Static Token FileK8s API server 在開啟時，可以設定一個檔案來記錄 token 與 user(group) 的 mapping 關係。 Client 連上 API server 時，只要能拿出此 token，便會被視為對應的 user 進行後續權限檢查。 此方式的優點為 設定簡單。需要新增/刪除使用者或修改 token 時，只需修改一個檔案 Token 可長可短，可以做出較為可讀的 kubeconfig 檔案 (行寬 80 字元以內) 此方式的缺點為 static token file 設定有異動時需要重開 server Service AccountService Account 是 K8s 原生設計給 K8s 內的 service 做 K8s 自我管理的機制。 此方式的優點為 彈性極高，可在 runtime 直接透過 K8s API 產生新的 service account 此方式的缺點為 service account 屬 namespaced resource，若有多個 namespace 要相同 user，需要重複設定 產生的 audit log 較難做事後梳理 K8s 有大量利用 service account 的自我管理行為，因此難以區隔使用者操作和 K8s 自身操作 相較於 X509 或 static token 方式，service account 不能直接設定群組 環境說明若使用 kubeadm 安裝設定 K8s cluster，只有 kubelet 會作為一個 system service 運行在 host 中。 其他如 K8s API server, scheduler 及 etcd 等都是跑在 master node 的 Docker container 環境中 以下說明均假設為此類環境進行操作。 設定 Static Token FileK8s Master Node 設定修改新增 user token file /etc/kubernetes/tokens.csv (路徑可自行調整) 12user-token,user-name,uid,&quot;optional-group,another-group&quot;fc27911e-73dd-46b0-8c57-86f2fe5fdd21,alice,alice@example.com,&quot;developer&quot; 檔案為單純的 CSV 格式，包含四個欄位 User Token: 任意字串，不一定要使用 UUID 格式 User Name: 使用此 token 身分驗證完成後得到的 user name UID: 用途不明，會出現在 audit log 中 identifies the end user and attempts to be more consistent and unique than username List of Group Name: (Optional) 使用此 token 身分驗證完成後得到的 group 身分 設好 static token file 後，修改 API server 的 static pod 描述 /etc/kubernetes/manifests/kube-apiserver.yaml。 user-tokens 的 path 與前述設定對齊。 12345678910111213141516171819202122232425262728293031diff --git a/root/manifests/kube-apiserver.yaml b/root/token-api-server.yamlindex 31c5f40..d4511ae 100644--- a/root/manifests/kube-apiserver.yaml+++ b/root/token-api-server.yaml@@ -37,6 +37,7 @@ spec: - --service-cluster-ip-range=10.96.0.0/12 - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key+ - --token-auth-file=/etc/kubernetes/tokens.csv image: k8s.gcr.io/kube-apiserver:v1.17.4 imagePullPolicy: IfNotPresent livenessProbe:@@ -71,6 +72,9 @@ spec: - mountPath: /usr/share/ca-certificates name: usr-share-ca-certificates readOnly: true+ - mountPath: /etc/kubernetes/tokens.csv+ name: user-tokens+ readOnly: true hostNetwork: true priorityClassName: system-cluster-critical volumes:@@ -98,4 +102,8 @@ spec: path: /usr/share/ca-certificates type: DirectoryOrCreate name: usr-share-ca-certificates+ - hostPath:+ path: /etc/kubernetes/tokens.csv+ type: FileOrCreate+ name: user-tokens status: {} 上述修改內容的重點為 將 master node 上的 user token 設定檔 mount 至 API server 的 container 內 設定 API server 去使用此 token 檔案 User Token File 後續維護若之後需要修改 user token file，因為一些上游的限制， API server pod 無法觀測到檔案的修改，即使 kill pod 再重啟也無法使用新的 token file。 不過我們可以透過修改 API server 描述檔的方式，穩定地重新部屬 API server，讓新的 token file 生效。 編輯 /etc/kubernetes/tokens.csv 修改 API server 描述檔 /etc/kubernetes/manifests/kube-apiserver.yaml 加入或修改 metadata.annotations.lastModify 欄位，填入合適字串 修改後 kubelet 會偵測到檔案異動，並重新 apply apiserver pod User kubeconfig 設定使用 kubectl 設定 user token kubectl config set-credentials &lt;user-name&gt; --token=&lt;token&gt; 或是直接修改 kubeconfig 內的 user object 123- name: alice user: token: fc27911e-73dd-46b0-8c57-86f2fe5fdd21 Log 設定當各個使用者操作 K8s 的身分確實有被切分開之後，即可進行後續的 audit log 設定動作。 Audit log 必須在吻合事先設定的 match rule 才會被記錄下來。 根據 Auditing 文件 說明， server 在判斷每個事件的 log level 時，是採取 first match 的規則進行。第一個吻合的規則會決定此事件是否紀錄以及紀錄的詳細程度。 The first matching rule sets the “audit level” of the event. API Server Audit 設定在 master node 上設定 audit policy /etc/kubernetes/audit-policy.yaml (路徑可自行調整) 123456789101112131415apiVersion: audit.k8s.io/v1kind: PolicyomitStages:- &quot;RequestReceived&quot;rules:- level: Metadata userGroups: - &quot;developer&quot; verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;, &quot;deletecollection&quot;]- level: Metadata userGroups: - &quot;developer&quot; resources: - group: &quot;&quot; resources: [&quot;secrets&quot;, &quot;configmaps&quot;] 此設定有幾個重點 global 的 omitStages 設定 所有 API request 都會經過 RequestReceived stage 省略此 stage 可以避免所有的 request 都產生兩筆 log Rule 以 userGroups 進行篩選 若已知要紀錄的 user group 範圍，明定 group 可避免記錄到大量的 K8s 自身維護的事件 設定動詞範圍記錄所有的 modify 操作 設定敏感的 resource 種類 (e.g. secrets &amp; configmaps) 記錄所有操作 接著修改 API server 的 static pod 描述 /etc/kubernetes/manifests/kube-apiserver.yaml。 audit hostPath volume 需與前述設定對齊 1234567891011121314151617181920212223242526272829303132333435363738394041diff --git a/root/token-api-server.yaml b/root/audit-token-api-server.yamlindex d4511ae..0e07f7f 100644--- a/root/token-api-server.yaml+++ b/root/audit-token-api-server.yaml@@ -38,6 +38,10 @@ spec: - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key - --token-auth-file=/etc/kubernetes/tokens.csv+ - --audit-policy-file=/etc/kubernetes/audit-policy.yaml+ - --audit-log-path=/var/log/kubernetes/audit.log+ - --audit-log-maxsize=1+ - --audit-log-maxbackup=6 image: k8s.gcr.io/kube-apiserver:v1.17.4 imagePullPolicy: IfNotPresent livenessProbe:@@ -75,6 +79,12 @@ spec: - mountPath: /etc/kubernetes/tokens.csv name: user-tokens readOnly: true+ - mountPath: /etc/kubernetes/audit-policy.yaml+ name: audit+ readOnly: true+ - mountPath: /var/log/kubernetes+ name: audit-log+ readOnly: false hostNetwork: true priorityClassName: system-cluster-critical volumes:@@ -106,4 +116,12 @@ spec: path: /etc/kubernetes/tokens.csv type: FileOrCreate name: user-tokens+ - name: audit+ hostPath:+ path: /etc/kubernetes/audit-policy.yaml+ type: File+ - name: audit-log+ hostPath:+ path: /var/log/kubernetes+ type: DirectoryOrCreate status: {} Note: 開 /var/log/kubernetes 資料夾而非單一 log 檔案，是為了避免 log rotate 時因權限不足無法正確 rotate 設定完之後即可在 master node 的 /var/log/kubernetes 看到 access log Sample 如下 command: kubectl apply -f services/tasks/redis-cluster-proxy.yml log: (Log 檔內會寫成一行，beautify 後如下) 12345678910111213141516171819202122232425262728293031323334353637{ &quot;kind&quot;:&quot;Event&quot;, &quot;apiVersion&quot;:&quot;audit.k8s.io/v1&quot;, &quot;level&quot;:&quot;Metadata&quot;, &quot;auditID&quot;:&quot;f09f32f4-a93f-41ee-b2b9-2f3acf3aa963&quot;, &quot;stage&quot;:&quot;ResponseComplete&quot;, &quot;requestURI&quot;:&quot;/api/v1/namespaces/alice/services&quot;, &quot;verb&quot;:&quot;create&quot;, &quot;user&quot;:{ &quot;username&quot;:&quot;alice&quot;, &quot;uid&quot;:&quot;alice@example.com&quot;, &quot;groups&quot;:[ &quot;developer&quot;, &quot;system:authenticated&quot; ] }, &quot;sourceIPs&quot;:[ &quot;10.300.400.512&quot; ], &quot;userAgent&quot;:&quot;kubectl/v1.18.2 (linux/amd64) kubernetes/52c56ce&quot;, &quot;objectRef&quot;:{ &quot;resource&quot;:&quot;services&quot;, &quot;namespace&quot;:&quot;alice&quot;, &quot;name&quot;:&quot;redis-cluster-proxy&quot;, &quot;apiVersion&quot;:&quot;v1&quot; }, &quot;responseStatus&quot;:{ &quot;metadata&quot;:{}, &quot;code&quot;:201 }, &quot;requestReceivedTimestamp&quot;:&quot;2020-10-21T12:27:30.252440Z&quot;, &quot;stageTimestamp&quot;:&quot;2020-10-21T12:27:30.272401Z&quot;, &quot;annotations&quot;:{ &quot;authorization.k8s.io/decision&quot;:&quot;allow&quot;, &quot;authorization.k8s.io/reason&quot;:&quot;RBAC: allowed by RoleBinding \\&quot;super-user-role-binding-alice/alice\\&quot; of Role \\&quot;super-user\\&quot; to User \\&quot;alice\\&quot;&quot; }} 疑難排解設定檔位置kubelet Static Pod 設定資料夾不一定在 /etc/kubernetes/manifests 位置， 須從 kubelet 啟動設定中的 staticPodPath 欄位找到真實位置。 備份設定檔若要備份 static pod 設定資料夾內的任何檔案，不能備份在相同資料夾內，否則會導致 kubelet 行為怪異。 Reload K8s API server 設定kubelet service 一般會自動偵測 static pod 資料夾內的檔案異動，並重新佈署該 pod，但偶爾還是會碰上意外.. 發生意外時，以下方式可能可以回到正常狀態 刪除對應的 pod, e.g. kubectl delete -n kube-system pod kube-apiserver-&lt;cluster name&gt; 刪除後 kubelet 會馬上重新佈署一個新的 API server Controlled By: Node/k8s-master: 意味者此 pod 不是由 deployment 等 K8s object 控制，是直接由 master node 控制 或是重啟 kubelet systemd service 後續此篇筆記紀錄 static token 的身分驗證機制，但若有企業規模的身分驗證需求時，這顯然不是個好方法。 Kubernetes 也有原生支援 OpenID 的身分驗證方式來應付更進一步的需求，不過這部分就等未來有空再來研究了。 References Authenticating | Kubernetes kubernetes - How can kube-apiserver be restarted? - Stack Overflow Auditing | Kubernetes Authorization Overview | Kubernetes kube-apiserver | Kubernetes kube-apiserver audit log rotation throwing permission denied · Issue #70664 · kubernetes/kubernetes AppendixRequest Stages: 123456789101112 +-----------------+ | RequestReceived +----+ +---+-------------+ | | | | +----------v------+ | | ResponseStarted | | +----------+------+ | | +-------+ | | | Panic |+----v------------+ | +-------+| ResponseComplete&lt;-----++-----------------+","link":"/2020/10/22/kubernetes-auditing.html"},{"title":"NATS 與 JetStream 簡易介紹","text":"最近因公司業務在玩一套相對新的 MQ: NATS。 因為官方文件不慎清楚且有些地方與直覺不同，造成起步緩慢。 以下簡單紀錄一下剛入門時應知道的事情。 Guide相較 RabbitMQ, Kafka 等，NATS 是一套較為年輕的 MQ。 雖然有部分子專案的版本未達 v1.0，但官方宣稱已經接近 production ready。 NATS 從一開始就是針對 cloud service 設計，cluster mode 的水平擴展， node 之間的身分驗證及 TLS 通訊設計看起來都還不錯。 NATS 的 message 並無特別限制，在 client library 內任何的 byte sequence 都可以成為 message。 NATS 有以下三個模式(以及其對應的 client library)。 NATS (NATS Core)NATS 專案從一開始發展時的基本模式。 支援 Pub/Sub pattern 並提供 at-most-once 語意。 NATS StreamingNATS Streaming 是一套疊在 NATS 上面形成的 solution。 因為設計上的問題，後來又有了 JetStream，所以我們基本上不用理它，只要知道 NATS Streaming 和 JetStream 不一樣，翻文件的時候不要翻錯即可。 JetStreamJetStream 是後來做在 NATS 內，可選擇是否啟用的子系統。 藉由 JetStream， 可以實作 Producer/Consumer pattern 並提供 at-least-once 語意。 Server side 沒什麼需要注意的，只要用較新版的 NATS image 並啟用設定即可。 Client 開發則需要注意一些概念。 Subject: NATS 最初的概念，代表一些 message 的集合。 Stream: 建立於一或多個 Subject 之上，可將這些 subject 內的 message 統整起來，並放入 persistent storage。 Consumer: 建立在某個 Stream 之下，可以依序的 consume 屬於此 stream 的特定 message。 需要注意的是，不只 Subject 與 Stream，Consumer 本身也是建立在 NATS server 中的一個物件。 當利用 client library create 一個 Consumer 時，並不是該 process 本身成為一個 consumer， 而是 NATS server 中被創了一個 Consumer 物件，準備去使用 Stream 裡面的 message。 JetStream client library 並沒有提供一個對稱的 producer/consumer API。 基於術語的限制以及為了避免誤會，以下在稱呼一般所稱的 producer/consumer 時， 會特別加上 role 後綴來表示。 Producer role: 要使用 NATS library 內的 Publish API，將產生的 message 推送至 某個 Subject 內。 Consumer role: 要使用 JetStream library 內的 Stream API，在 NATS server 上對目標 Subject 建立 Stream，接著使用 JetStream Consumer API，在 NATS server 中 建立屬於該 Stream 的 Consumer。以上都完成之後，即可利用 Consumer 上的 NextMsg 來 消耗 message。 ConclusionJetStream 的 API 設計並不常見，需要先認知到與既有設計的差別之處才能開始開發。 不過其 cloud native 的架構設計或許可以在維運上面勝過其他老牌的 MQ solution。 今天就先寫到這裡，如果有哪天有興趣再補吧。 :D Reference Comparing NATS, NATS Streaming and NATS JetStream | by George Koulouris | Medium AppendixGolang sample code: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;log&quot; &quot;math/rand&quot; &quot;os&quot; &quot;testing&quot; &quot;time&quot; &quot;github.com/nats-io/jsm.go&quot; &quot;github.com/nats-io/jsm.go/api&quot; &quot;github.com/nats-io/nats.go&quot;)var fullSubject string = &quot;report_task.scheduled&quot;var wildcardSubject string = &quot;report_task.*&quot;func consumeOne(doneChan chan bool) { msg, err := consumer.NextMsg() if err != nil { fmt.Printf(&quot;Fail to get message: %v\\n&quot;, err) } fmt.Printf(&quot;Consume get task: %s\\n&quot;, string(msg.Data)) time.Sleep(2 * time.Second) if err := msg.Ack(); err != nil { fmt.Printf(&quot;Fail to ack the message %s: %v\\n&quot;, string(msg.Data), err) } doneChan &lt;- true}func TestProduceAndConsume(t *testing.T) { producerStopChan := make(chan bool) consumerStopChan := make(chan bool) var taskCount int = 1 go func() { for idx := 0; idx &lt; taskCount; idx++ { taskName := fmt.Sprintf(&quot;task #%d&quot;, rand.Int()) nc.Publish(fullSubject, []byte(taskName)) fmt.Printf(&quot;Producer produce: %s\\n&quot;, taskName) } producerStopChan &lt;- true }() for idx := 0; idx &lt; taskCount; idx++ { go func() { consumeOne(consumerStopChan) }() } &lt;-producerStopChan for idx := 0; idx &lt; taskCount; idx++ { &lt;-consumerStopChan } fmt.Println(&quot;Done&quot;)}var ctx context.Contextvar cancel context.CancelFuncvar nc *nats.Connvar stream *jsm.Streamvar consumer *jsm.Consumerfunc setup() { var err error ctx, cancel = context.WithTimeout(context.Background(), 10*time.Second) nc, err = nats.Connect(nats.DefaultURL, nats.UserInfo(&quot;name&quot;, &quot;password&quot;), nats.UseOldRequestStyle()) if err != nil { log.Fatal(err) } jsmgr, err := jsm.New(nc) if err != nil { log.Fatal(err) } streamName := &quot;ReportTask&quot; stream, err = jsmgr.LoadOrNewStreamFromDefault(streamName, api.StreamConfig{ Subjects: []string{wildcardSubject}, Storage: api.FileStorage, Retention: api.LimitsPolicy, Discard: api.DiscardOld, MaxConsumers: -1, MaxMsgs: -1, MaxBytes: -1, MaxAge: 24 * time.Hour, MaxMsgSize: -1, Replicas: 1, NoAck: false, }) if err != nil { log.Fatal(err) } consumerName := &quot;Generator&quot; consumer, err = stream.LoadOrNewConsumerFromDefault(consumerName, api.ConsumerConfig{ Durable: consumerName, DeliverPolicy: api.DeliverNew, FilterSubject: fullSubject, AckPolicy: api.AckExplicit, AckWait: 30 * time.Second, MaxDeliver: 5, ReplayPolicy: api.ReplayInstant, SampleFrequency: &quot;0%&quot;, }) if err != nil { log.Fatal(err) }}func shutdown() { cancel()}func TestMain(m *testing.M) { setup() code := m.Run() shutdown() os.Exit(code)}","link":"/2021/07/28/nats-brief-intro.html"},{"title":"在 macOS 上架設 Apache 與 PHP-FPM","text":"工作上因為一些特殊需求，需要在 macOS 環境下架設 Apache + PHP-FPM 的使用環境。好在 macOS 本來就有預裝 Apache 以及 PHP-FPM，並提供 Apache 的 launchd 設定檔，要在 macOS 上架設這個服務並不困難。 本文介紹如何以最低限度的設定，在 macOS 上跑 Apache + PHP-FPM。以筆記的方式呈現，不會有太多的講解。 Notes 筆者是在 macOS 10.14 與 10.15 上測試此流程 macOS 系統上，/etc 是一個 symblic link 連至 /private/etc， /var, /tmp 也有相同行為。 設定與啟用 PHP-FPM複製並修改 PHP-FPM 設定檔系統內有會自帶 PHP-FPM 的 default 設定檔，將其複製一份出來，並修改內容。 12$ sudo cp /etc/php-fpm.conf.default /etc/php-fpm.conf$ sudo cp /etc/php-fpm.d/www.conf.default /etc/php-fpm.d/www.conf 將執行身分從 nobody 修改為 _www (與 Apache httpd一致)。 1$ sudo vim /etc/php-fpm.d/www.conf 12345; Unix user/group of processes; Note: The user is mandatory. If the group is not set, the default user's group; will be used.user = _wwwgroup = _www 修改 error_log，調整 log file 的路徑。 1$ sudo vim /etc/php-fpm.conf 123456; Error log file; If it's set to &quot;syslog&quot;, log is sent to syslogd instead of being written; into a local file.; Note: the default prefix is /usr/var; Default Value: log/php-fpm.logerror_log = /var/log/php-fpm.log 新增 PHP-FPM 的 launchd 設定檔並啟用創一個 launchd daemon 設定檔給 PHP-FPM 使用， 此舉目的為讓 PHP-FPM daemon 可以在 macOS 開機時自己啟用。 建議將設定檔放在 /Library/LaunchDaemons 下，參照 launchd 的文件， 此位置是供第三方軟體擺放 daemon 設定使用。 1$ sudo vim /Library/LaunchDaemons/com.example.php-fpm.plist 1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE plist PUBLIC &quot;-//Apple//DTD PLIST 1.0//EN&quot; &quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&gt;&lt;plist version=&quot;1.0&quot;&gt;&lt;dict&gt; &lt;key&gt;Disabled&lt;/key&gt; &lt;true/&gt; &lt;key&gt;Label&lt;/key&gt; &lt;string&gt;com.example.php-fpm&lt;/string&gt; &lt;key&gt;ProgramArguments&lt;/key&gt; &lt;array&gt; &lt;string&gt;/usr/sbin/php-fpm&lt;/string&gt; &lt;string&gt;--nodaemonize&lt;/string&gt; &lt;/array&gt; &lt;key&gt;OnDemand&lt;/key&gt; &lt;false/&gt;&lt;/dict&gt;&lt;/plist&gt; 做好設定檔之後，用 launchctl 指令 load 此設定檔，並下參數告訴 macOS 之後此 daemon 要在開機時預設啟用。 1$ sudo launchctl load -w /Library/LaunchDaemons/com.example.php-fpm.plist 上述指令執行完後， launchd 會把 PHP-FPM daemon 叫起。 1234$ ps aux | grep php_www 515 0.0 0.0 4297608 648 ?? S 6:18PM 0:00.00 /usr/sbin/php-fpm_www 514 0.0 0.0 4305800 628 ?? S 6:18PM 0:00.00 /usr/sbin/php-fpmroot 513 0.0 0.0 4305800 784 ?? Ss 6:18PM 0:00.00 /usr/sbin/php-fpm 設定並啟用 Apache Web Server修改設定檔，讓 Apache 使用 proxy_module 與 proxy_fcgi_module， 並確認 php7_module 沒被啟用。 需要本文的讀者應該不至於把 Apache PHP module 與 PHP-FPM 搞混.. XD 1$ sudo vim /etc/apache2/httpd.conf 123LoadModule proxy_module libexec/apache2/mod_proxy.soLoadModule proxy_fcgi_module libexec/apache2/mod_proxy_fcgi.so# LoadModule php7_module libexec/apache2/libphp7.so 在 &lt;Directory &quot;/Library/WebServer/Documents&quot;&gt; 或其他需要的地方內， 加入 PHP 的 handler，指向 PHP-FPM 預設提供服務的 socket。 1234567&lt;Directory &quot;/Library/WebServer/Documents&quot;&gt;... 上略 &lt;FilesMatch \\.php$&gt; SetHandler &quot;proxy:fcgi://localhost:9000/&quot; &lt;/FilesMatch&gt;&lt;/Directory&gt; Apache 的 daemon config 本來就存在於系統目錄內，但 Disable 的值被設為 true， 用下述 command 將 Apache daemon load 進 launchd 內，並讓 launchd 記錄此 daemon 應被啟用。 1sudo launchctl load -w /System/Library/LaunchDaemons/org.apache.httpd.plist 與 PHP-FPM 相同，此指令下去之後，launchd 就會把 Apache 拉起。 此時可去 http://localhost/ 確認，如果看到大大的標題寫著 It works! 即代表 Apache 有順利執行。 確認 PHP-FPM 運作正常丟一個 phpinfo 到 web server 的預設根目錄下。 1$ sudo vim /Library/WebServer/Documents/phpinfo.php 123&lt;?php phpinfo();?&gt; 之後連上 http://localhost/phpinfo.php ，看到 Server API 為 FPM/FastCGI 即可。 :D Useful Links A launchd Tutorial","link":"/2019/11/09/run-apache-and-php-fpm-in-macos.html"},{"title":"在 Ubuntu Server 上自動啟用 SSH Agent","text":"當 我們的 SSH private key 有上 pass phrase 保護時， SSH agent 是個方便的好東西。因為它可以幫我們記住已經解鎖過的 private key。 可惜的是，Ubuntu server 18.04 的環境預設並不會幫你生一個 SSH agent 出來。 本文章記錄一點摸索的過程… 系統自帶的 SSH agent systemd unit 我看別人的 Ubuntu 登入之後就有 SSH agent 可以用啊？ 很可惜的是我的環境沒有。研究一陣子之後，發現 SSH agent 應是在有圖形介面 的情況下才會被自動帶起。 在 dpkg --listfiles openssh-client 下可看到幾個重要的檔案 /usr/lib/openssh/launch-agent /usr/lib/systemd/user/ssh-agent.service /usr/lib/systemd/user/graphical-session-pre.target.wants/ssh-agent.service 看了這幾個檔案的內容後可得知 這是設計給圖形介面的登入 session 使用的 service 即使想要直接 enable ssh-agent.service 也無法，因為裡面沒有寫任何的 [Install] 參數 自行撰寫並啟用一個 SSH agent 服務為了解決沒有 SSH agent 的問題，我們可以自己寫一個 systemd 的 user service， 讓系統在發現我登入之後，自動幫我把 SSH agent 拉起來。 首先編輯 ~/.local/share/systemd/user/ssh-agent.service (參考 man systemd.unit 此為預設的 user unit 路徑) 123456789[Unit]Description=SSH authentication agent[Service]ExecStart=/usr/bin/ssh-agent -a %t/ssh-agent.socket -DType=simple[Install]WantedBy=default.target 注意 ssh-agent 的 -D 參數與 Type=simple 設定。 接著執行 systemctl --user enable ssh-agent.service。 這一步會在 .config/systemd/user/default.target.wants 資料夾下創出一個 symbolic link， 連回剛剛我們寫的 service file，表示要在登入時自動啟用此 unit。 接著重新登入該機器，應該就可以看到一個 ssh-agent process 跑起來了。 設定 SSH agent 所需的的環境變數雖然 SSH agent 起來了，但此時若下 ssh-add -L 依然會發現無法連上 SSH agent。 Could not open a connection to your authentication agent. 這是因為 ssh 以及 ssh-add 等工具預設都是看 SSH_AUTH_SOCK 環境變數來得知 要透過哪個 Unix socket 與 agent 溝通。 為了處理此問題，我們需在 ~/.profile 內加入一行環境變數設定，確保在登入時能自動設定完成。 1export SSH_AUTH_SOCK=&quot;$XDG_RUNTIME_DIR/ssh-agent.socket&quot; 註: $XDG_RUNTIME_DIR/ssh-agent.socket 與前述 unit file 內的 -a %t/ssh-agent.socket 對應。詳細可參考 man systemd.unit 下次登入重新讀取 profile 之後即可正常使用 SSH agent 囉。 :D Alternative Solution尋找解決方式的過程中，注意到了一些解法，透過純 shell script 的方式處理重複登入的問題 1234567891011121314151617SSH_ENV=&quot;$HOME/.ssh/environment&quot;function start_agent { /usr/bin/ssh-agent | sed 's/^echo/#echo/' &gt; &quot;${SSH_ENV}&quot; chmod 600 &quot;${SSH_ENV}&quot; . &quot;${SSH_ENV}&quot; &gt; /dev/null /usr/bin/ssh-add;}if [ -f &quot;${SSH_ENV}&quot; ]; then . &quot;${SSH_ENV}&quot; &gt; /dev/null ps -ef | grep ${SSH_AGENT_PID} | grep ssh-agent$ &gt; /dev/null || { start_agent; }else start_agent;fi Ref: https://stackoverflow.com/questions/18880024/start-ssh-agent-on-login/18915067#18915067 若不考慮 race condition，該作法其實也很值得參考。可以在沒有 systemd 輔助的的生態系底下使用。 雜談看 systemd 的文件時，發現 systemd 的 user mode 會非常遵守 XDG_ 系列的環境變數。 不過因為我們是在 Ubuntu server edition 下，所以大部分都略過不看。 :D 但 XDG_RUNTIME_DIR 這個變數除外，此變數雖然也是由 XDG Base Directory Specification 所規範，但在一般 Linux 發行版，此變數是由 pam_systemd 直接維護的。所以即使是在 server 環境也會有此變數存在。 References systemd.unit command line - What is XDG_RUNTIME_DIR? - Ask Ubuntu XDG Base Directory Specification Add user ssh-agent as daemon to Ubuntu 18.04LTS server. git - Start ssh-agent on login - Stack Overflow","link":"/2020/04/04/run-ssh-agent-ubuntu-server.html"},{"title":"Samba 內檔案的異常執行權限","text":"許多場合會利用 Samba 來建立給所有工作者共用的 SMB 工作目錄。 SMB 是 Microsoft 針對 Windows 體系設計的 protocol，但因為種種因素， 目前 Mac 及各 Linux 桌面發行版也都有不錯的 SMB client 支援。 已 SMB 提供共用的工作目錄，似乎已成為最常見的協同工作方法。 在另一方面，Samba 是一套基於 Unix 環境開發的開源 SMB server 實作。 但因為 Windows 與 Unix 在檔案系統上設計的根本性差別，儘管 Samba 歷史悠久且功能齊全， 仍然會有一些先天性的問題。 為了解釋問題到底從何而來，以下要簡單介紹一下 Windows 與 Unix 的檔案相關特性。 Windows File Attribute 與 Unix File Mode傳統上，Windows 系統下的每個檔案都會需要有以下四個屬性: Archive: 紀錄此檔案在上次備份後是否更動過。 Hidden: 紀錄此檔案是否要隱藏。Windows 內建 dir 或檔案總管均會遵從此設定。 System: 紀錄此檔案是否爲系統檔案。 Read-only: 紀錄此檔案是否只能讀取。 Unix 作業系統採取了與 Windows 不同的設計。 在 Unix 內，每個檔案紀錄針對檔案擁有者、檔案擁有群組及其他人分別紀錄三組權限 Readable: 檔案是否可讀取 Writable： 檔案是否可寫入 Executable： 檔案是否可執行 現在我們可以知道，Windows 與 Unix 對於檔案應該紀錄的特性/模式其實有不一樣的要求。 許多和檔案系統相關的功能也會用不同的方式來達成。 比方說，有關檔案 是否隱藏 這件事情，在 Windows 上會有一個獨立的 attribute 來處理。 而在 Unix 上，則是依據 “. 開頭的檔案應被隱藏” 的常規。除了檔名看起來有點不一樣之外， 隱藏檔案和一般檔案在檔案系統裡沒有差別。 另外我們也可以注意到Windows 和 Unix 對於 可執行 這個概念的處理方式也不同。 在 Unix 的世界中，每個檔案的 mode 中會紀錄這個檔案是否可執行。而在 Windows 中， 檔案並沒有是否可執行的概念，而是讓作業系統維護一個表單，裡面紀錄各種副檔名的檔案應該如何開啟或執行。 Samba 的設計與產生的問題Samba 是個 SMB 的 server 實作，作為在 Unix 環境上跑的服務，但同時也要支援 Windows 的 file attribute，亦即前述提到的 Archive、Read-only 等。這些 attribute 是必得以某種 方式存在 Samba server 上。在這裏 Samba 的實作非常有趣： 利用 Unix 環境中 Windows 用不到的 executable bit 來存放 Windows 需要的 file attribute。 具體來說，Archive、System 與 Hidden 屬性會分別存在擁有者、擁有群組與其他人的 file mode 的 executable bit 當中。而 Read-only 則是影響檔案擁有者的寫入權限是開啟。 簡單圖示如下: 123456 Owner Group Others +----------------------------+ | r w x r w x r w x | +-^--^--^--------^--------^--+ | | | | |ReadOnly Archive System Hidden 但此做法舉其實會導致其他問題。這會其他在 Mac 或 Unix 環境下掛載 SMB share 的使用者， 會看到檔案有時莫名的變成可執行，或原本可執行的 script 突然變成不可執行。 於是乎，在 Window 與 Linux 混用的工作環境中，RD 的 terminal 下常會看到一片花花綠綠的 source code 資料夾。(一般 shell 都會預設開 ls 的 colorize 選項) Executable Bit 異常的解決方式若要避免 Samba 的這類行為，可以在 smb.conf 中加入以下設定 1234map archive = nomap system = nomap hidden = nomap read only = no 如此 Samba 就不會嘗試利用 Unix 的 file mode 來存放這些 attribute。 又或是如果想支援 Windows 的 attribute，但又不想影響 Unix 下的執行權限，可以將這些 attribute 寫進 extended attributes 裡。這需要使用以下設定 1store dos attributes = yes 碎碎唸作為一個軟體工程師，常聽到 Every detail matters 或其他類似精神的標語。 魔鬼蔵在細節裏，確保每個細節的正確(或至少看起來正確)是每個工程師都應該追求的境界。 而這個追求細節的精神，必須從乾淨的工作環境開始做起。 為什麼會寫出這邊文章？其實就只看到公司的 VCS 內各種怪異的檔案權限， 感到困惑而已。清楚的變數命名、符合直覺的 API 設計有助於開發人員理解專案。正確的檔案權限 其實也是如此。設定檔應該是 rw-，script 應該是 r-x，不違背直覺的專案狀態才不會 阻礙工程師工作。 當然，一切的根本原因還是在於 Samba 的預設設定會把 Archive attribute map 到 file mode 裡面。在 Window 環境工作的工程師一般都是在無意的情況下把 file mode 的異動 寫道 VCS 裡面。這時只能抱怨爲何當年 Samba 的作者要做出這種設計了。 相關連結 Why are files in a smbfs mounted share created with executable bit set? File Permissions and Attributes on MS-DOS and Unix Document: attrib command Document: File attribute API Official Samba Config Document","link":"/2018/04/17/samba-executable-bit.html"},{"title":"單台機器的 Ceph 部署","text":"原由Ceph 的預設設定對資料的 replica 行為要求嚴格。 若只有單台機器或是硬碟數量受限，往往架設起來的 Ceph 無法順利存放資料。 此篇筆記關注的目標如下 若想要用最少資源，建立可用的 Ceph 環境，需要做哪些額外的調整？ 背景知識Ceph 是一套開源的儲存叢集 solution。 可以整合多個儲存設備並在其上提供 RADOSGW, RBD, Ceph FS 等不同層級的存取介面。 對於每個儲存設備 (HDD, SSD)，Ceph 會建立對應的 OSD 來管理儲存設備。 有了儲存設備之後，Ceph 會建立邏輯上的 pool 作為管理空間的單位。 Pool 底下會有多個 PG(placement group) 作為實際存放資料至 OSD 中的區塊。 在 Ceph 的預設設定中，一般 pool 的 replica 行為如下 要有三份 replica replica 要分散在不同的 host 上 在開發環境中，資料掉了其實並無傷大雅，三份 replica 意味著儲存空間的浪費。 且若資料真的要放在不同的 host 上，連同 replica 三份這點，我們就至少要開三台機器， 增加無謂的管理成本。 解決方式假設我們都是透過 cephadm bootstrap 來架設 Ceph。 Ceph cluster 建立好，也設定完需要的 OSD 之後，就可以來建立 pool。 根據 pool 的目的不同，要解決單台機器部署 Ceph 的限制，大概會有兩種做法。 降低 Pool SizePool size 此術語意味著該 pool 下的 PG 要 replica 幾份。 若某 pool 是拿供他人存放資料，或是會使用較多空間的，可以把 size 降為 1。 調整完之後就相當於該 pool 內的所有資料都不會有 replica。 範例如下: 123ceph osd pool create &quot;&lt;pool name&gt;&quot;ceph osd pool set &quot;&lt;pool name&gt;&quot; size 1ceph osd pool application enable &quot;&lt;pool name&gt;&quot; rbd 調整 Choose Leaf 行為Ceph 有定義不同層級的資料分散設定。 預設值為 host，意味著只有一台機器的情況下，資料會無法複製。 若調整為 osd，只要該機器上有多顆硬碟即可滿足複製條件。 若是針對 Ceph 自行建立出來，管理 meta data 的 pool (e.g. device_health_metrics) 可以考慮使用此方式處理。 設定方式大概有兩種。 方法一: 調整 Ceph global 設定 編輯 /etc/ceph.conf 並在 global section 下加入 osd_crush_chooseleaf_type 設定 123[global]... osd_crush_chooseleaf_type = 0 或是直接執行 command 1ceph config set global osd_crush_chooseleaf_type 0 這邊的 0 代表 OSD。預設的對應列表如下 123456type 0 osdtype 1 host...type 9 zonetype 10 regiontype 11 root 方法二: 修改 crush map 內容 筆者有注意到有時即使有執行方法一，pool 還是不會受到設定影響。 (相關知識還太少， 不太確定具體原因) 不過針對此狀況，還有第二個方法可以使用。 此方法會用到 crushtool 指令 (Ubuntu 中需要額外安裝 ceph-base 套件) 首先執行指令將目前的 crush map 撈出來 12ceph osd getcrushmap -o &quot;compiled-crush-map&quot;crushtool -d &quot;compiled-crush-map&quot; -o &quot;crush-map&quot; 接著修改 crush-map 檔案內容，應該會有一行有 step chooseleaf 開頭的設定，把最後的 type 從 host 調整為 osd。 1234# Beforestep chooseleaf firstn &lt;number&gt; type host# Afterstep chooseleaf firstn &lt;number&gt; type osd 最後將修改好的 crush map 設定塞回去。 12crushtool -c &quot;crush-map&quot; -o &quot;compiled-crush-map&quot;ceph osd setcrushmap -i &quot;compiled-crush-map&quot; 相關 reference link Common Settings — Ceph Documentation Chapter 4. Create a Cluster Red Hat Ceph Storage 1.2.3 | Red Hat Customer Portal CRUSH Maps — Ceph Documentation Manually editing a CRUSH Map — Ceph Documentation CRUSH Maps — Ceph Documentation 結語筆者在公司業務並不負責維護 production 的 Ceph cluster，僅是為了建立 Kubernetes 開發環境，需要有個基本會動的 Ceph。 為了用最少資源建立 Ceph 環境，需要調整相關設定來改變 Ceph 行為。 只可惜相關的資源不是很夠，一路跌跌撞撞下來，決定寫下這篇筆記，希望造福未來的自己，也同時照顧他人。","link":"/2021/08/08/single-node-ceph-cluster.html"},{"title":"利用 SSH 建立 SOCKS Proxy","text":"最近因為疫情又開始 WFH 了。 公司有提供一些 VPN solution 讓員工存取公司內網路， 但有一些架在 public cloud 上的服務後台因為有擋來源 IP，無法在家直接存取。 這時候 SSH 內建的 SOCKS proxy server 功能就可以派上用場了！ SSH 可以在建立連線時，一併在本機端開出一個 SOCKS (version 4 and 5) 的 server， 接下來任何應用程式都可以將任意的 TCP 連線透過這個 SOCKS server，轉送到 SSH server 後再與目標站台連線。 因為大家一定在公司裡有台可以 SSH 的機器(?)，於是這種限制公司 IP 的管理後台就可以順利存取。 :D 使用方式很簡單，SSH 連線時多下參數即可。 1ssh &quot;target-machine&quot; -D &quot;localhost:1080&quot; -N -D localhost:1080: 決定要開在 local 的 SOCKS port，RFC 建議是 1080 -N: 如果不需要開一個 shell，只是要 SOCKS proxy 功能，那可以多帶此參數 Note: SSH 有支援 SOCKS5 (可做 IPv6 proxy) 但不支援 authentication，不過因為 SOCKS server 可以如上述設定只開在 localhost 上，所以沒麼問題。 接著我們就可以設定 OS 層級或是 application 層級的 proxy 設定來使用這個 proxy 了！ 以我一開始遇到的問題來說，通常我會多開一個 Firefox 並設定使用 proxy 來存取公司的各種管理後台。 這樣就可以保持其他網路流量還是直接往外打，不需要過 proxy。 :D 若要快速啟動 proxy，可以使用 Windows Terminal 並設定一個 profile，執行上述 SSH 指令。 PuTTY 作為 Windows 上最多人使用的 SSH client，也有支援 SOCKS proxy 功能， 詳見: How To Set up a SOCKS Proxy Using Putty &amp; SSH - Security Musings Reference ssh(1): OpenSSH SSH client - Linux man page linux - How can I setup a SOCKS proxy over ssh with password based authentication on CentOS? - Server Fault","link":"/2022/04/20/ssh-socks-proxy.html"},{"title":"如何避免 Commit Message 拼錯字？","text":"文件打錯字還好，隨時可以修。 但在 commit message 中打錯字，可是會流傳千古。 身為一個 RD，有個極簡的解決方法.. 把底下這行設定放到 .vimrc 內即可。 (O 1autocmd FileType gitcommit setlocal spell (對於屬 Git commit message 的 buffer 自動啟用 spell check 功能) 設定完之後，當出現 vim 不認識的單字時，就會有醒目的顏色提示， 提醒自己該回頭看一下是不是又拼錯字了。 當然，要有舒適的拼字檢查體驗，字典檔的維護也是很重要的一環。 不過那又是另一個話題了.. Reference Vim Spell-Checking Vim: spell.txt","link":"/2021/09/28/vim-git-commit-spell-check.html"},{"title":"VS Code 新功能: Remote Repositories","text":"VS Code 在 1.57 版中， Remote Development 系列 extension 加入了新成員: Remote Repositories。 有了這個 extension 之後，如果遇上臨時想看的 project，就可以直接在 VS Code 中叫出來看，不需要事先 clone 至某個 local 資料夾。 不過.. 因為這個 extension 實際上是建一個 Virtual Workspaces 並把 code 放在裡面閱覽， 所以用 Remote Repositories 開出來的 workspace 功能非常受限。 諸如 Debug, Terminal 及大部分的 extension 基本上都不能用。 但話雖如此，當看 code 看一看想要開始進行比較深入的修改及除錯時， 其實也是有提供轉換成一般 workspace 的功能。 使用上非常方便！ 可惜的是，目前此 extension 支援的 remote repository 種類只有 GitHub。 且如同其他 Remote Development Series，這個 extension 並非 open source project： Visual Studio Code Remote Development Frequently Asked Questions Cannot use Remote Development extension pack · Issue #196 · VSCodium/vscodium 未來會不會支援 GitHub 以外的 Git repositories，甚至其他種類的 VCS， 只能看微軟爸爸的眼色了。","link":"/2021/06/12/vscode-feature-remote-repositories.html"},{"title":"GitLab 更換自家 GPG Key","text":"今天 GitLab 在自家 blog 上公告 revoke 簽署 package 的 GPG key。 We recently became aware of an instance where this key and other tokens used to distribute official GitLab Runner packages and binaries were not secured according to GitLab’s security policies. We have not found any evidence of unauthorized modification of the packages or access to the services storing them. 並不是因為 key 被 compromise，僅是因為 key 不符合公司的安全規範，所以就進行了一次 rekey。 GPG key rekey 並不如換憑證一樣，只要重簽一張就好 (因為信賴建立在已知的第三方 CA 上)。 GPG key rekey 需要透過可信管道重新宣告 fingerprint 並請大家 import 新的 key。 這個轉換的成本，相較換憑證應是高非常多且難以量化的。 沒想到居然僅為了不合安全規範就進行 rekey，不愧是國際一線的軟體公司！ See: The GPG key used to sign GitLab Runner packages has been rotated | GitLab","link":"/2021/06/17/gitlab-revoke-gpg-key.html"},{"title":"GitHub 即日起支援使用 Security Key 進行 Git 操作","text":"GitHub 開始支援使用 security key 進行 Git 操作啦！ 這應該是各家科技巨頭當中，第一個支援 security key 進行 SSH login 的服務吧。 筆者昨天 5/10 才在公司內分享如何使用 security key 來做 SSH login， 沒想到 Yubico 和 GitHub 也剛好在昨天一起同步更新 blog 文章，通知大家這個新功能。 喜極而泣.. Security keys are now supported for SSH Git operations - The GitHub Blog GitHub now supports SSH security keys - Yubico 以下簡單介紹如何使用這個新功能。 為了方便解說及避免誤會，後述內容均以正式名稱 authenticator 代稱 security key。 如何使用首先當然要有一把 authenticator，如果還沒有，趕快去買一把囉。 :D 第一步，在 authenticator 內產生新的 key pair。 產生 key pair 的流程和傳統放在檔案系統上的差不多，只是 key type 要指定代表 authenticator 的 type。 1ssh-keygen -t ecdsa-sk 產生的過程，根據不同的 authenticator，會有要求按一下 且/或 輸入 PIN code 驗證身分。 此步驟會在 authenticator 內產生一組 key pair，並將 public key 寫到檔案系統上。 平常放 private key 的那個檔案還是會產生，不過這次裡面放的會是一個 key handle。 第二步，透過 GitHub 的 web UI 上傳 public key 上傳完之後，沒意外就可以順利使用了，可以試著 clone 一些 project 1234$ git clone git@github.com:github/secure_headers.gitCloning into 'secure_headers'...Confirm user presence for key ECDSA-SK SHA256:........User presence confirmed 若確認 OK，之後的 Git 操作都可以透過隨身攜帶的 authenticator 保護， 只要按一下 authenticator 即可。 設定完之後，若沒有拿出 authenticator，就不能進行 push / pull 操作。 只要確保 authenticator 還在身上，就可以安心睡大覺。 (再也不用擔心 private key 放在公司電腦上會被摸走了！) 進階使用方式FIDO 2 authenticator 博大精深，除了上述的基本使用流程外，還有些細節可以設定。 以下分別介紹三個進階使用技巧： 要求身分驗證 (User Verification) 才能使用 Authenticator根據每個人平常保管鑰匙習慣的差異，可能有人會擔心 authenticator 真的被摸走。 但 authenticator 也有支援一定要驗甚身分 (e.g. PIN code or 指紋辨識) 後才能 使用內部的 key pair 的功能。 要如何使用呢？ 只要在產生 key pair 的過程中多下一個 flag 即可。 1ssh-keygen -t ecdsa-sk -O verify-required 若之後要使用由此方式產生的 key pair，除了手指按一下 authenticator 之外，還會要求 使用者輸入 PIN code 才能順利完成操作。如此即使 authenticator 被偷走了，也不用太緊張。 全自動使用 Authenticator (避免 User Presence Check)若把 authenticator 插上電腦後，想要隨時隨地都進行 push / pull， 但不要每次都手按一下 authenticator。這種自動化的使用情境 OpenSSH 其實也是有支援的。 使用的方式也是在產生 key pair 時多帶一個參數。 1ssh-keygen -t ecdsa-sk -O no-touch-required 同時在將 public key 部屬到目標機器上時，在 public key 該行前面多下 no-touch-required 即可。 (詳情請見 ssh-keygen(1) 及 sshd(8)) 以此方始產生的 key pair 在使用時就不需要每次都手按一下，可以全自動使用。 不過，雖然 OpenSSH 有支援此種使用情境，但目前 GitHub 禁止這種使用方式。 節錄自上述 blog 文章 While we understand the appeal of removing the need for the taps, we determined our current approach to require presence and intention is the best balance between usability and security. 所以在 GitHub 上，若想要全自動操作，只能回去用一般的 SSH key 或 API token 囉。 避免手動複製 Key Handle前面有提到，原先檔案系統上用來放 private key 的檔案會變成拿來擺放 key handle。 這意味著，當我們想在新的機器上透過 SSH 進行 Git 操作時，除了拿出 authenticator 之外， 也需要把原先的 key handle 檔案複製到新的機器上。 且若 key handle 檔案掉了，該組 key pair 就不能使用了。 若要避免此問題，就要用上 authenticator 的另一個進階功能 discoverable credentials / resident keys 。 1ssh-keygen -t ecdsa-sk -O resident 使用此類型的 key pair 時，會在 authenticator 上消耗一些儲存空間。但換來的好處是， 使用者可以在新的機器上，把 key handle 從 authenticator 內抽出來。 1ssh-keygen -K # extract discoverable credentials 如此就不用手動複製擺放 key handle 的 private key 檔案了。 但要注意的是此類型 key pair 會消耗 authenticator 的空間。 每把 authenticator 可以放多少 key pair 要再自行查閱官方文件。 結語以上介紹了基本使用情境及三種可能的進階使用方式。 筆者在 2014 年第一次注意到 FIDO (U2F) 標準，當時就在想像沒有密碼的世界。 如今，藉由 FIDO 2 security key 的普及，當初所想的美好願景似乎在慢慢地實現中.. 希望未來能看到 security key 運用在更多場景上！","link":"/2021/05/11/github-ssh-fido-key.html"}],"tags":[{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"secret","slug":"secret","link":"/tags/secret/"},{"name":"security","slug":"security","link":"/tags/security/"},{"name":"email","slug":"email","link":"/tags/email/"},{"name":"rfc","slug":"rfc","link":"/tags/rfc/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"jekyll","slug":"jekyll","link":"/tags/jekyll/"},{"name":"gitlab","slug":"gitlab","link":"/tags/gitlab/"},{"name":"golang","slug":"golang","link":"/tags/golang/"},{"name":"community","slug":"community","link":"/tags/community/"},{"name":"generic","slug":"generic","link":"/tags/generic/"},{"name":"gnupg","slug":"gnupg","link":"/tags/gnupg/"},{"name":"kubernetes","slug":"kubernetes","link":"/tags/kubernetes/"},{"name":"log","slug":"log","link":"/tags/log/"},{"name":"authentication","slug":"authentication","link":"/tags/authentication/"},{"name":"nats","slug":"nats","link":"/tags/nats/"},{"name":"mq","slug":"mq","link":"/tags/mq/"},{"name":"fido","slug":"fido","link":"/tags/fido/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"systemd","slug":"systemd","link":"/tags/systemd/"},{"name":"samba","slug":"samba","link":"/tags/samba/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"ceph","slug":"ceph","link":"/tags/ceph/"},{"name":"socks","slug":"socks","link":"/tags/socks/"},{"name":"vim","slug":"vim","link":"/tags/vim/"},{"name":"spell","slug":"spell","link":"/tags/spell/"},{"name":"ide","slug":"ide","link":"/tags/ide/"},{"name":"vscode","slug":"vscode","link":"/tags/vscode/"},{"name":"development","slug":"development","link":"/tags/development/"}],"categories":[{"name":"notes","slug":"notes","link":"/categories/notes/"},{"name":"news","slug":"news","link":"/categories/news/"},{"name":"tips","slug":"tips","link":"/categories/tips/"}]}